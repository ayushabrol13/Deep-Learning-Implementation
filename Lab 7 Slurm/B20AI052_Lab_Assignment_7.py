# -*- coding: utf-8 -*-
"""lab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cW3XvdtExK7Ow530USyw8M_6xSltACHP

# Deep Learning - Lab Assignment 7

    Ayush Abrol B20AI052

---
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt

import torch
import torch.optim as optim
import torchvision
import torch.utils.data
from torch import nn, optim
from torch.nn import functional as F
from torchvision import datasets, transforms
import torchvision.models as models
import copy
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

"""### Using the FashionMNIST dataset and creating dataloader using different transforms"""

transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
])

print("Downloading the dataset...")

trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,
                                            shuffle=True, num_workers=2)

testset = torchvision.datasets.FashionMNIST(root='./data', train=False,
                                        download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64,
                                        shuffle=False, num_workers=2)

print("Dataset downloaded!")

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')

print("Train data shape: ", trainloader.dataset.train_data.shape)
print("Test data shape: ", testloader.dataset.test_data.shape)

print("Train labels shape: ", trainloader.dataset.train_labels.shape)
print("Test labels shape: ", testloader.dataset.test_labels.shape)

plt.figure(figsize=(20,20))
for i in range(100):
    plt.subplot(10,10,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(trainset.data[i])
    plt.xlabel(trainset.classes[trainset.targets[i]], color='white')
plt.savefig('images/fashion_mnist.png')

# Load the pretrained ResNet-18 from pytorch
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(512, 10)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

import timeit

# Train the model and measure the time using timeit
def train(model, trainloader, criterion, optimizer, epochs=10):
    train_losses = []
    train_acc = []
    model.train()
    for epoch in range(epochs):
        running_loss = 0.0
        running_acc = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            inputs = torch.cat((inputs, inputs, inputs), 1)
            inputs = inputs.to(device)
            labels = labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            running_acc += (predicted == labels).sum().item()
        train_losses.append(running_loss/len(trainloader))
        train_acc.append(running_acc/len(trainloader.dataset))
        print('Epoch: {}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch+1, running_loss/len(trainloader), running_acc/len(trainloader.dataset)))
    return train_losses, train_acc

start = timeit.default_timer()
print("Training the model for 10 epochs")
train_losses, train_acc = train(model, trainloader, criterion, optimizer, epochs=10)
stop = timeit.default_timer()
print('Time taken for 10 epochs: ', stop - start)

# Plot the training loss and accuracy
plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.plot(train_losses)
plt.title("Training Loss")
plt.subplot(1,2,2)
plt.plot(train_acc)
plt.title("Training Accuracy")
plt.savefig('images/train_loss_acc_10eps.png')

# Save the model
torch.save(model.state_dict(), 'models/model_10eps.pth')

model.eval()
test_loss = 0
correct = 0
with torch.no_grad():
    for data, target in testloader:
        data = torch.cat((data, data, data), 1)
        data = data.to(device)
        target = target.to(device)
        output = model(data)
        test_loss += criterion(output, target).item() # sum up batch loss
        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability
        correct += pred.eq(target.view_as(pred)).sum().item()

test_loss /= len(testloader.dataset)

print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
    test_loss, correct, len(testloader.dataset),
    100. * correct / len(testloader.dataset)))

model2 = models.resnet18(pretrained=True)
model2.fc = nn.Linear(512, 10)
model2 = model2.to(device)

criterion2 = nn.CrossEntropyLoss()
optimizer2 = optim.Adam(model2.parameters(), lr=0.001)

start = timeit.default_timer()
print("Training the model for 15 epochs")
train_losses2, train_acc2 = train(model2, trainloader, criterion2, optimizer2, epochs=15)
stop = timeit.default_timer()
print('Time taken for 15 epochs: ', stop - start)

# Plot the training loss and accuracy
plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.plot(train_losses2)
plt.title("Training Loss")
plt.subplot(1,2,2)
plt.plot(train_acc2)
plt.title("Training Accuracy")
plt.savefig('images/train_loss_acc_15eps.png')

# Save the model
torch.save(model2.state_dict(), 'models/model_15eps.pth')

model2.eval()
test_loss = 0
correct = 0
with torch.no_grad():
    for data, target in testloader:
        data = torch.cat((data, data, data), 1)
        data = data.to(device)
        target = target.to(device)
        output = model2(data)
        test_loss += criterion2(output, target).item() # sum up batch loss
        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability
        correct += pred.eq(target.view_as(pred)).sum().item()
        
test_loss /= len(testloader.dataset)

print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(
    test_loss, correct, len(testloader.dataset),
    100. * correct / len(testloader.dataset)))

# Hyperparameter tuning
learning_rates = [0.001, 0.0001, 0.00001]
momentums = [0.9, 0.99, 0.999]
weight_decays = [0.0001, 0.001, 0.01]
tuning_results = []

for lr in learning_rates:
    for momentum in momentums:
        for weight_decay in weight_decays:
            model = models.resnet18(pretrained=True)
            model.fc = nn.Linear(512, 10)
            model = model.to(device)
            criterion = nn.CrossEntropyLoss()
            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)
            train_losses, train_acc = train(model, trainloader, criterion, optimizer, epochs=10)
            model.eval()
            test_loss = 0
            correct = 0
            with torch.no_grad():
                for data, target in testloader:
                    data = torch.cat((data, data, data), 1)
                    data = data.to(device)
                    target = target.to(device)
                    output = model(data)
                    test_loss += criterion(output, target).item() # sum up batch loss
                    pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability
                    correct += pred.eq(target.view_as(pred)).sum().item()
            test_loss /= len(testloader.dataset)
            tuning_results.append([lr, momentum, weight_decay, train_losses[-1], train_acc[-1], test_loss, correct/len(testloader.dataset)])
            # Save the model
            torch.save(model.state_dict(), 'models/model_10eps_lr{}_mom{}_wd{}.pth'.format(lr, momentum, weight_decay))

tuning_results = pd.DataFrame(tuning_results, columns=['lr', 'momentum', 'weight_decay', 'train_loss', 'train_acc', 'test_loss', 'test_acc'])
tuning_results.to_csv('tuning_results.csv', index=False)

bestmodel = None
bestacc = 0

for i in range(len(tuning_results)):
    if tuning_results['test_acc'][i] > bestacc:
        bestacc = tuning_results['test_acc'][i]
        bestmodel = tuning_results.iloc[i]

print("Best model: ", bestmodel)
print("Best accuracy: ", bestacc)
print("Learning rate: ", bestmodel['lr'])
print("Momentum: ", bestmodel['momentum'])
print("Weight decay: ", bestmodel['weight_decay'])